# RL

This `Multi-armed Bandits` folder consists of implementation of various algorithms including epsilon-greedy
exploration, UCB, KL-UCB, and Thompson Sampling for a multi-armed bandit problem.
